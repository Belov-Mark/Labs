import re

print("–¢–µ—Å—Ç—ã normalize")

def normalize(text, *, casefold = True, yo2e = True):
    text = re.sub(r"[\t\r\n\f\v]", " ", text)

    if yo2e:
        text = text.replace("—ë", "–µ").replace("–Å", "–ï")

    if casefold:
        text = text.casefold()

    text = re.sub(r" +", " ", text)

    return text.strip()

tests = [
    "–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t",
    "—ë–∂–∏–∫, –Å–ª–∫–∞",
    "Hello\r\nWorld",
    "  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "
]

for array in tests:
    result = normalize(array)
    print(f"{array} - {result}")

print("\n")


print("–¢–µ—Å—Ç—ã tokenize")

def tokenize(text):
    pattern = r"\b[\w]+(?:-[\w]+)*\b"
    return re.findall(pattern, text)

tests = [
    "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä",
    "hello,world!!!",
    "–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ",
    "2025 –≥–æ–¥",
    "emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"
]

for array in tests:
    result = tokenize(array)
    print(f"{array} - {result}")

print("\n")


print("–¢–µ—Å—Ç—ã count_freq –∏ top_n")

def count_freq(tokens):
    freq = {}
    for token in tokens:
        freq[token] = freq.get(token, 0) + 1
    return freq

def top_n(freq, n = 2):
    sorted_items = sorted(freq.items(), key=lambda x: (-x[1], x[0]))
    return sorted_items[:n]

tests = [
    ["a", "b", "a", "c", "b", "a"],
    ["bb", "aa", "bb", "aa", "cc"]
]

for array in tests:
    result = top_n(count_freq((array)))
    print(f"{array} - {result}")
